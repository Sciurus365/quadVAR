---
title: '1'
author: "Jingmeng Cui"
date: "2023-12-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# simulation

(from `Projects\\2023_nonlinear_networks\\code\\1.rmd`)

```{r}
sim_NVAR_model1 <- function(time = 5000, init = c(1.3, 1.3, 4.8, 4.8), sd = 0.2){
  output <- matrix(nrow = time, ncol = 5)
  colnames(output) <- c("time", "x1", "x2", "x3", "x4")
  output[,1] <- 1:time
  output[1,2:5] <- init
  for(i in 2:time) {
    x1 <- output[i-1, 2]
    x2 <- output[i-1, 3]
    x3 <- output[i-1, 4]
    x4 <- output[i-1, 5]
    x1_1 <- x1 + (1.6+1*x1-0.2*x1^2 +0.04*x1*x2-0.2*x1*x3-0.2*x1*x4) * 0.5 +rnorm(1, sd = sd)
    x2_1 <- x2 + (1.6+1*x2-0.2*x2^2 +0.04*x1*x2-0.2*x2*x3-0.2*x2*x4) * 0.5 +rnorm(1, sd = sd)
    x3_1 <- x3 + (1.6+1*x3-0.2*x3^2 +0.04*x3*x4-0.2*x1*x3-0.2*x2*x3) * 0.5 +rnorm(1, sd = sd)
    x4_1 <- x4 + (1.6+1*x4-0.2*x4^2 +0.04*x3*x4-0.2*x1*x4-0.2*x2*x4) * 0.5 +rnorm(1, sd = sd)
    output[i,2:5] <- c(x1_1, x2_1, x3_1, x4_1)
  }
  return(output)
}
set.seed(1614)
data3 <- sim_NVAR_model1(sd = 1, time = 200)
ggplot2::qplot(data = data3 |> as.data.frame(), x = time, y = x3)
```
```{r}
library(devtools)
load_all()

sim_model1 <- NVAR(data3, vars = colnames(data3)[2:5], tune = "EBIC")
print(sim_model1)
sim_model1$NVAR_model[[1]]
```


# empirical data


```{r}
library(readr)
data_s1 <- read_csv("data_s1.csv")
data_s2 <- read_csv("data_s2.csv")
```
```{r}
library(devtools)
load_all()
model1 <- NVAR(data_s1, vars = colnames(data_s1), tune = "EBIC")
model1_ <- NVAR(data_s1, vars = colnames(data_s1), tune = "BIC")
print(model1)
print(model1_)

model2 <- NVAR(data_s1[1:75,], vars = colnames(data_s1), tune = "EBIC")
model2_ <- NVAR(data_s1[1:75,], vars = colnames(data_s1), tune = "BIC")
print(model2)
print(model2_)


# bistable dataset
model3 <- NVAR(data_s2, vars = colnames(data_s2), tune = "EBIC")
model3_ <- NVAR(data_s2, vars = colnames(data_s2), tune = "BIC")
print(model3)
print(model3_)

model4 <- NVAR(data_s2[700:799,], vars = colnames(data_s2), tune = "EBIC")
model4_ <- NVAR(data_s2[700:799,], vars = colnames(data_s2), tune = "BIC")
print(model4) # NVAR is good here
print(model4_)


```

```{r}


# check if df is correct
# test with the bistable simulation model
```

# model importance

```{r}
vi1 <- vip::vi_firm(model1$best_model[[1]], train = model1$data_tidy)
vi1

par(mfrow = c(2, 3))
for (name in vi1$Variable) {
  plot(attr(vi1, which = "effects")[[name]], type = "l", ylim = c(6, 8), las = 1)
}
```

```{r}
vi2 <- vip::vi_firm(model2$best_model[[1]], train = model1$data_tidy)
vi2

par(mfrow = c(2, 3))
for (name in vi2$Variable) {
  plot(attr(vi2, which = "effects")[[name]], type = "l", ylim = c(6, 8), las = 1)
}
```
Worked in principle. But:
1. Too many models, AIC under-estimated. -> EBIC?
2. Best model meaningful or not? unstandardized, not ortho, may contain higher order terms without lower order terms.

“Let the computer find out” is a poor strategy and usually reflects the fact that the researcher did not bother to think clearly about the problem of interest and its scientific setting (Burnham and Anderson, 2002).

# new comparison between regularized AR, VAR, and RAMP

### relationship between AICs in different packages/functions and test for the consistency in this package

taken from the example of RAMP::RAMP

```{r}
set.seed(0)
n = 500
p = 3 #Can be changed to a much larger number say 50000
x = matrix(rnorm(n*p),n,p)
eta = 1 * x[,1] + 2 * x[,2] + 3* x[,3]
y =  eta + rnorm(n)

temp1 <- RAMP::RAMP(X = x, y = y, penalty = "MCP", tune = "AIC")
temp1
with(temp1, cri.list[cri.loc]) + n + n*log(2*pi) + 4
temp1$df[temp1$cri.loc]
temp1_ <- RAMP::RAMP(X = x, y = y, penalty = "MCP", tune = "BIC")
with(temp1_, cri.list[cri.loc]) + n + n*log(2*pi) + 2*log(n)


temp2 <- SIS::tune.fit(x = x, y = y, penalty = "MCP", tune = "aic")
c(temp2$a0, temp2$beta)
temp2$fit %>% AIC %>% min
temp2$fit %>% BIC %>% min
temp2$ic <- temp2$fit %>% AIC %>% min
temp2_ <- tune.fit(x = x, y = y, penalty = "MCP", tune = "bic")

temp3 <- lm(y ~ x[,1] + x[,2] + x[,3])
temp3
AIC(temp3)
extractAIC(temp3)[2] + n + n*log(2*pi) + 2
extractAIC(temp3, k = log(n))[2] + n + n*log(2*pi) + log(n)
# there is a 2k in the AIC formula. AIC() counts variance and intercept for k, extractAIC() only counts intercept for k, RAMP counts neither variance nor intercept for k.

temp_mimic_NVAR <- structure(
  list(
    AR_model = list(temp3),
    VAR_model = list(temp2),
    NVAR_model = list(temp1),
    tune = "AIC"
  ), class = "NVAR"
)
print(temp_mimic_NVAR)

temp_mimic_NVAR_ <- structure(
  list(
    AR_model = list(temp3),
    VAR_model = list(temp2_),
    NVAR_model = list(temp1_),
    tune = "BIC"
  ), class = "NVAR"
)
print(temp_mimic_NVAR_)


temp1_BIC <- RAMP::RAMP(X = x, y = y, penalty = "MCP", tune = "BIC")
temp1_EBIC <- RAMP::RAMP(X = x, y = y, penalty = "MCP", tune = "EBIC")
exp(temp1_EBIC$cri.list - temp1_BIC$cri.list)
temp1_EBIC$df


## ebic and bic are the same for ncvreg when all the variables are selected. but for RAMP, when all the main effects are selected, but no interaction is selected, ebic is larger than bic.
```

